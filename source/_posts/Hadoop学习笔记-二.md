---
title: Hadoop学习笔记(二)之HDFS
date: 2020-04-17 15:27:21
tags: hadoop
categories: hadoop
---

<center>Author：闫玉良</center>

 `Hadoop` 之分布式文件系统，你了解吗？

官方文档汇总：https://www.pythonnote.cn/OfficialDocuments/

> 包含了后端常使用的各种文档，小闫静心制作，快收藏起来吧 ~

<!--more-->

***更多精彩文章请关注公众号『Pythonnote』或者『全栈技术精选』***

# HDFS

## 1.HDFS 入门

### 1.1 背景

面对各行各业日益增长的数据量，普通的机器无论在存储空间还是管理能力上都显得力不从心。既然单台机器的资源有限，那么增加机器的方式是否可行？答案是肯定的，于是乎出现了分布式的概念。分布式文件管理系统便可以将一堆机器组合在一起，并隐藏细节，让用户感觉与之前单机储存文件毫无差别，但其实文件是通过网络来访问的。

### 1.2 简介

1) 官方称：`HDFS` 可以运行在廉价的服务器上，为海量的数据存储提供了高容错、高可靠性、高可扩展性、高获得性、高吞吐率等特征。

2) `HDFS` 基于开源的 `GFS` 开发实现。

3) `HDFS` 的默认存储单位是数据块 `Block`，默认数据块大小是 `64MB` 。文件存储时会分成一个个数据块，但是当一个小文件没达到数据块大小时，文件是多大就占用多大的空间。

4) `NameNode` 称为元数据节点，管理保存所有的节点信息、文件信息等等。它的一些系统文件我们需要了解：`edits` 保存了一些操作信息；`fsimage` 是名字空间文件。

5) 数据节点 `DataNode` 是存储数据的地方，一个文件会被分成若干个数据块储存在对应的数据节点上。数据节点的系统文件：以 `blk_` 开头无后缀的文件保存的就是数据块，以 `blk_` 开头以 `.meta` 结尾的文件则保存对应数据块的属性信息，`subdir` 开头的目录保存的也是数据块相关信息（数据块太多了，就一起放在这种目录下）。

6) 从元数据节点 `Secondary Name Node` 虽然名字中有个「从」字，但并非是备份，而是与 `Name Node` 各司其职，它主要的作用是隔一段时间合并一下日志文件等，并帮助 `Name Node` 将内存中的元数据信息 `checkpoint` 到硬盘上。

> `checkpoint` 即检查点，保存某一刻内存数据到硬盘的文件中。

### 1.3 优点

1) 可以处理超大文件（`MB` 到 `TB` 级别）

2) 对于服务器要求不高，`Hadoop` 集群可部署在廉价的机器上节约项目成本，因为它的多副本，使你不必担心宕机等意外事故带来的影响。

3) 一次写入，多次读取。

4) 现在还支持对已有文件追加内容。

### 1.4 缺点

1) 不适合低延迟数据访问，即访问数据时间可能会长一些。

2) 不适合存储大量小文件。因为存储一个文件，其元数据会保存在 `NameNode` 中，而 `NameNode` 的内存决定了 `HDFS` 储存文件的上限，大量小文件会耗费资源。

> 文件存储后，其元数据（文件的相关信息，如创建日期，文件大小，存储路径等等）会保存在 `NameNode` 中。一个小文件和一个大文件的元数据大小是差不多的，元数据存储满后，不再接受文件存储。如果存储大量的小文件，会导致存储空间上的浪费，还会增加 `NameNode` 的压力，从而影响集群性能。可以采用 `Sequence File` 等方式对小文件进行合并，或者使用 `Name Node Federation` 的方式改善。

### 1.5 设计目标

1) 集群中管理数量庞大的服务器，如何做到错误检测，快速、自动恢复是核心目标。

2) 需要高数据传输带宽，保证支撑数以千万计的文件。

3) 需要支持大文件存储。

4) 移动计算而非移动数据。

### 1.6 架构

1) `HDFS` 采用 `master/slave` 架构。

2) 一个 `HDFS` 集群由一个 `NameNode` 和一些 `DataNode` 组成， `NameNode` 相当于控制中心，负责管理文件系统的名字空间、数据块与数据节点的映射以及数据节点的调度。 `DataNode` 则负责处理实际的客户端读写的请求，存储数据。

## 2.HDFS 基本操作

### 2.1 HDFS shell

> 先启动 `Hadoop` 才能使用

1) 列出文件目录，同 `ls`：

```shell
hadoop fs -ls 目录路径
```

> 递归的查看文件可以使用 `-R` 参数

```shell
# 列出 /data 下的所有文件
hadoop fs -ls -R /data
```

2) 在 `HDFS` 中创建文件夹

```shell
hadoop fs -mkdir 文件夹名称
```

> 如果想嵌套（级联）的创建目录，可以使用 `-p` 参数

3) 上传文件到 `HDFS`

```shell
hadoop fs -put 本地文件路径 HDFS文件路径
```

4) 从 `HDFS` 上下载文件

```shell
hadoop fs -get HDFS文件路径 本地路径
```

5) 查看 `HDFS` 上某个文件内容

```shell
hadoop fs -cat HDFS上文件路径 
```

6) 统计目录下各文件的大小

```shell
hadoop fs -du 目录路径
```

7) 删除  `HDFS` 上某个文件或文件夹

```shell
hadoop fs -rm 文件
hadoop fs -rmdir 文件夹
```

8) 帮助命令

```shell
hadoop fs -help 命令
```

## 3.HDFS 运行原理

### 3.1 读流程

客户端通过 `RPC` 调用 `NameNode` 的相关方法，如果客户端身份验证成功，会获取到要读取的文件对应的数据块保存在哪些 `DataNode` 上；客户端向 `DataNode` 发起读取的请求，获取数据（客户端读取的是连续的流，但实际过程是先到最近的 `DataNode` 读取数据，读取完之后连接关闭，再去读取下一个 `DataNode` 上的数据块）；当所有的数据读取完成后，资源关闭。

### 3.2 写流程

客户端向 `NameNode` 发起  `RPC` 请求创建文件， `NameNode` 验证用户权限、检测文件是否存在，最终创建一条元数据信息，然后客户端开始向 `DataNode` 保存数据，进行切分并完成第一个副本的创建，再将其复制到其他的节点上，直到所有的节点完成后，关闭连接。

### 3.3 副本

`HDFS` 上文件对应的数据块保存有多个副本，并为其提供容错机制，当副本丢失或者宕机时，能够快速自动恢复。但是要注意，我们需要对副本系数进行设置，而且此系数一经写入，不可更改。

#### 3.3.1 摆放策略

第一个副本放置在上传文件的 `Data Node` 上，如果是在集群外提交，则根据磁盘速度以及 `CPU` 效率选取一个节点。

第二个副本放在与第一个副本不同机架的节点上。

第三个副本放在与第二个副本相同机架的不同节点上。

更多的副本就随机放在节点中。

### 3.4 负载均衡

1) 如果某个 `DataNode` 上空闲空间低于临界点，按照负载均衡策略，系统会自动将数据转移到其他空闲的 `DataNode` 上。

2) 如果对某个文件的请求突然增加，有可能启动一个计划来创建该文件新的副本，最后再重新平衡集群中其他数据。

3) `HDFS` 会调整存储分布以均衡 `IO` 性能，平衡 `IO` 负载，平均数据，平衡集群。

4) `Hadoop` 的 `bin/start-balancer.sh` 脚本可以启动均衡服务。使用 `-threshold` 参数设置判断集群是否平衡的阈值；使用 `hdfs-site.xml` 文件中的 `dfs.balance.bandwidth` 设置 `Balancer` 运行时允许占用的带宽。 

## 4.HDFS 高级知识

### 4.1 序列化机制

1) 序列化：将对象转化为字节流，以便在网络上传输或者写在磁盘上持久化存储。

2) 反序列化：将字节流转回成对象。

3) `Hadoop` 中多个节点进程间通讯是通过 `RPC` 完成的，所以需要序列化机制。

4) `Hadoop` 序列化中，用户可以复用对象，减少了 `java` 对象的分配和回收，提高应用效率。

### 4.2 Sequence File

#### 4.2.1 概述

前面我们介绍过，当 `HDFS` 中保存有大量的小文件时，`NameNode` 压力会很大，使得存储的元数据信息非常多，而 `Sequence File` 则可以将小文件合并。

1) `Sequence File` 是 `Hadoop` 提供的一种对二进制文件的支持。

2) 二进制文件直接将键值对序列化到文件中。

3) 使用 `Sequence File` 进行存储的文件，占用空间会大于原数据，因为为了查找方便，`Sequence File` 的存储中添加了一些额外的信息，使得数据增大。

#### 4.2.2 特点

1) 支持压缩。分为基于 `Record` 和 `Block` 压缩，前一种只压缩值不压缩键，后一种则是键和值都压缩。默认为无压缩，每个记录（`Record`）是由它的记录长度（字节数）、键的长度、键和值组成。

2) 对于 `MapReduce` 任务十分友好，因为文件可以被切分，使用 `Map Task` 并行处理可大幅提高作业的执行效率。

3) 使用简单，因为 `Hadoop` 提供了 `API` ，业务逻辑中应用便捷。

### 4.3 Map File

`Map File` 是排序过的 `Sequence File` ，由 `index` 和 `data` 两部分组成。`index` 是文件的数据索引，主要记录了每个 `Record` 的 `key` 值以及该  `Record` 在文件中的偏移位置。在 `Map File` 被访问的时候，索引文件会先被加载到内存，通过 `index` 映射关系可快速定位到指定 `Record` 所在文件位置。所以 `Map File` 比 `Sequence File` 检索效率更高，缺点便是维护多余的 `index` 数据，占用了部分内存。

> 学习自《基于Hadoop与Spark的大数据开发实战》

***更多精彩文章请关注公众号『Pythonnote』或者『全栈技术精选』***

